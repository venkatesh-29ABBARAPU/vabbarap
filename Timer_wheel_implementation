/*
 * per-CPU timer vector definitions:
 */
#define TVN_BITS (CONFIG_BASE_SMALL ? 4 : 6) ==> 6
#define TVR_BITS (CONFIG_BASE_SMALL ? 6 : 8) ==> 8
#define TVN_SIZE (1 << TVN_BITS) ===> 1<<6 == 64
#define TVR_SIZE (1 << TVR_BITS) ===> 1<<8 == 256
#define TVN_MASK (TVN_SIZE - 1)===>63
#define TVR_MASK (TVR_SIZE - 1)===>255

//TVR_SIZE = 1 << 8 = 256
//TVN_SIZE = 1 << 6 = 64

struct tvec {
	struct list_head vec[TVN_SIZE];==>vec[64]
};
struct tvec_root {
	struct list_head vec[TVR_SIZE];==>vec[256]
};
struct tvec_base {
	spinlock_t lock;
	struct timer_list *running_timer;
	unsigned long timer_jiffies;
	unsigned long next_timer;
	struct tvec_root tv1;
	struct tvec tv2;
	struct tvec tv3;
	struct tvec tv4;
	struct tvec tv5;
} ____cacheline_aligned;
struct tvec_base boot_tvec_bases;
EXPORT_SYMBOL(boot_tvec_bases);
static DEFINE_PER_CPU(struct tvec_base *, tvec_bases) = &boot_tvec_bases;


struct timer_list {
	struct list_head entry;
	unsigned long expires;
	struct tvec_base *base;
	void (*function)(unsigned long);
	unsigned long data;
};

#define INDEX(N) ((base->timer_jiffies >> (TVR_BITS + (N) * TVN_BITS)) & TVN_MASK)

The Big Picture: Hierarchical Timer Wheels
Linux uses multiple timer wheels for efficiency:
tv1: 256 buckets, finest granularity (0-255 jiffies)
tv2: 64 buckets, next level (256-16383 jiffies)
tv3: 64 buckets, next level (16384-1048575 jiffies)
tv4: 64 buckets, coarsest level (1048576-∞ jiffies)


static inline int timer_pending(const struct timer_list * timer)
{
	return timer->entry.next != NULL;
}
=========================================================================================================
🔹 What is detach_timer()?
When a timer in Linux is expired or re-queued, it needs to be detached from the hash bucket list (tv1..tv5).
That’s what detach_timer() does: it unlinks the timer safely from whatever list it is in.
==========================================================================================================
static inline void detach_timer(struct timer_list *timer, int clear_pending)
{
    if (timer_pending(timer)) {
        list_del(&timer->entry);
        if (clear_pending)
            timer->entry.next = NULL;
    }
}

void add_timer(struct timer_list *timer)
{
	BUG_ON(timer_pending(timer));
	mod_timer(timer, timer->expires);
}

int mod_timer(struct timer_list *timer, unsigned long expires)
{
  	return __mod_timer(timer, expires, false, TIMER_NOT_PINNED);
}

static inline int __mod_timer(struct timer_list *timer, unsigned long expires, bool pending_only, int pinned)
{
    	base = lock_timer_base(timer, &flags);
	   if (timer_pending(timer)) {
		        detach_timer(timer, 0);
		        if (timer->expires == base->next_timer)
			        base->next_timer = base->timer_jiffies;
		          ret = 1;
	  } 
	timer->expires = expires;
	if (time_before(timer->expires, base->next_timer))
      		base->next_timer = timer->expires;
	internal_add_timer(base, timer);
}

static void internal_add_timer(struct tvec_base *base, struct timer_list *timer)
{
    unsigned long expires = timer->expires;
    unsigned long idx = expires - base->timer_jiffies;
    struct list_head *vec;

    if (idx < TVR_SIZE) {
        // Near expiry → put into tv1
        int i = expires & TVR_MASK;
        vec = base->tv1.vec + i;
    } else if (idx < 1 << (TVR_BITS + TVN_BITS)) {
        // Goes into tv2
        int i = (expires >> TVR_BITS) & TVN_MASK;
        vec = base->tv2.vec + i;
    } else if (idx < 1 << (TVR_BITS + 2*TVN_BITS)) {
        // Goes into tv3
        int i = (expires >> (TVR_BITS + TVN_BITS)) & TVN_MASK;
        vec = base->tv3.vec + i;
    } else if (idx < 1 << (TVR_BITS + 3*TVN_BITS)) {
        // Goes into tv4
        int i = (expires >> (TVR_BITS + 2*TVN_BITS)) & TVN_MASK;
        vec = base->tv4.vec + i;
    } else if ((long)idx < 0) {
        // Already expired → run soon
        vec = base->tv1.vec + (base->timer_jiffies & TVR_MASK);
    } else {
        // Far future → goes into tv5
        int i = (expires >> (TVR_BITS + 4*TVN_BITS)) & TVN_MASK;
        vec = base->tv5.vec + i;
    }

    // Link timer into chosen bucket
    list_add_tail(&timer->entry, vec);
}
==================================================================================
2. What’s happening?
base->timer_jiffies = the "current time" in the timer wheel for this CPU.
timer->expires = the absolute expiry time (in jiffies).

idx = expires - timer_jiffies = how far in the future the timer is.

Then:
If it’s very near (fits in tv1 slots), it goes to tv1. Otherwise it goes to tv2, tv3, … up to tv5.
The exact bucket index is chosen using bit shifts & masks.

3. Example Walkthrough
Setup

Assume:
TVR_BITS = 8 → 256 slots in tv1
TVN_BITS = 6 → 64 slots in tv2–tv5

Current base->timer_jiffies = 1000

Step-by-step
1. Timer with expires=1005
idx = 1005-1000=5 (<256) → goes to tv1.
Slot = 1005 & 0xFF = 229.
Stored in tv1.vec[229].
2. Timer with expires=1100
idx = 100.
100 < 256 → goes to tv1.
Slot = 1100 & 0xFF = 76.
Stored in tv1.vec[76].
3. Timer with expires=1200
idx = 200.
200 < 256 → tv1.
Slot = 1200 & 0xFF = 176.
Stored in tv1.vec[176].

4. Timer with expires=2000
idx = 1000.
1000 >= 256, but 1000 < (1 << (8+6)) = 16384 → goes to tv2.
Slot = (2000 >> 8) & 63 = 7.
Stored in tv2.vec[7].
5. Timer with expires=5000
idx = 4000.
Still <16384 → tv2.
Slot = (5000 >> 8) & 63 = 19.
Stored in tv2.vec[19].
6. Timer with expires=100000
idx = 99000.
Too large for tv2 (<16384) but <1 << (8+2*6) = 1,048,576 → goes to tv3.
Slot = (100000 >> (8+6)) & 63 = 24.
Stored in tv3.vec[24].

Diagram (simplified)
 tv1 (256 slots)                  tv2 (64 slots)             tv3 (64 slots)
 ┌───────┐                        ┌───────┐                  ┌───────┐
 │ vec[76]  → Timer(exp=1100)     │ vec[7]  → Timer(2000)    │ vec[24] → Timer(100000)
 │ vec[176] → Timer(exp=1200)     │ vec[19] → Timer(5000)    │
 │ vec[229] → Timer(exp=1005)     │                          │
 └───────┘                        └───────┘                  └───────┘

======================================When Timer Interrupt occurs===============================================================================
/*
 * This function runs timers and the timer-tq in bottom half context.
 */
static void run_timer_softirq(struct softirq_action *h)
{
	struct tvec_base *base = __this_cpu_read(tvec_bases);
	
	if (time_after_eq(jiffies, base->timer_jiffies))
		__run_timers(base);
}


#define INDEX(0) ((base->timer_jiffies >> (8 + (0) * 6)) & 63) ===> (base->timer_jiffies >> 8) & 63
#define INDEX(1) ((base->timer_jiffies >> (8 + (1) * 6)) & 63) ===> (base->timer_jiffies >> 14) & 63
#define INDEX(2) ((base->timer_jiffies >> (8 + (2) * 6)) & 63  ===> (base->timer_jiffies >> 20) & 63
#define INDEX(3) ((base->timer_jiffies >> (8 + (3) * 6)) & 63  ===> (base->timer_jiffies >> 26) & 63

 * __run_timers - run all expired timers (if any) on this CPU.
 * @base: the timer vector to be processed.
 *
 * This function cascades all vectors and executes all expired timer
 * vectors.
 */
static inline void __run_timers(struct tvec_base *base)
{
	struct timer_list *timer;
	spin_lock_irq(&base->lock);

	while (time_after_eq(jiffies, base->timer_jiffies)) {
		struct list_head work_list;
		struct list_head *head = &work_list;
		int index = base->timer_jiffies & TVR_MASK;
		/*
		 * Cascade timers:
		 */
		if (!index && (!cascade(base, &base->tv2, INDEX(0))) &&
				      (!cascade(base, &base->tv3, INDEX(1))) &&
					   !cascade(base, &base->tv4, INDEX(2)))
			  cascade(base, &base->tv5, INDEX(3));
===========================Above if condition can be rewritten as below for better understanding==========
    if (index == 0) {
         if (cascade(base, &base->tv2, INDEX(0)) == 0) {
             if (cascade(base, &base->tv3, INDEX(1)) == 0) {
                 if (cascade(base, &base->tv4, INDEX(2)) == 0) {
                       cascade(base, &base->tv5, INDEX(3));
                 }
           }
       }
   }
=========================================================================================================
		++base->timer_jiffies; //The value of base->timer_jiffies represents the last tick (in terms jiffies) for which timers have been processed in the current timer base.
                               🧠 What is base->timer_jiffies?
                                 • It tracks the progress of timer execution within this timer base.
                                 • Initially, it might be set to the current value of jiffies.
                                 • As timers are processed, base->timer_jiffies is incremented to reflect that timers up to that tick have been handled.

		list_replace_init(base->tv1.vec + index, &work_list);//	Moves all timers from slot index of tv1 into work_list.
																Leaves tv1.vec[index] empty.Then we walk through work_list and re-add each timer via 
																internal_add_timer() to the proper level (maybe tv1 again, maybe tv2, etc.).
	
		while (!list_empty(head)) {
			void (*fn)(unsigned long);
			unsigned long data;
			timer = list_first_entry(head, struct timer_list,entry);
			fn = timer->function;
			data = timer->data;
			
			base->running_timer = timer;
			detach_timer(timer, 1);
			spin_unlock_irq(&base->lock);
			//call_timer_fn(timer, fn, data);-->this calls internally fn(data) with having multiple trace points
			fn(data);
			spin_lock_irq(&base->lock);
		}
	}
	base->running_timer = NULL;
	spin_unlock_irq(&base->lock);
}

==============================================================================================
int cascade(tvec_base_t *base, tvec_t *tv, int index) {
    int moved = 0;
    
    // Get the current slot in tv2 that needs cascading
    struct list_head *slot = &tv->vec[index];
    
    // Move all timers from this slot to appropriate tv1 slots
    while (!list_empty(slot)) {
        timer_t *timer = list_first_entry(slot, timer_t, entry);
        list_del(&timer->entry);
        
        // Calculate new expiration time relative to current base
        unsigned long expires = timer->expires;
        unsigned long idx = expires - base->timer_jiffies;
        
        // Add to correct tv1 slot
        int new_slot = idx & TVR_MASK;  // TVR_MASK = 0xFF (256 slots)
        list_add_tail(&timer->entry, &base->tv1.vec[new_slot]);
        
        moved++;
    }
    
    return moved;
}


static int cascade(struct tvec_base *base, struct tvec *tv, int index)
{
	/* cascade all the timers from tv up one level */
	struct timer_list *timer, *tmp;
	struct list_head tv_list;
	list_replace_init(tv->vec + index, &tv_list);
	/* We are removing _all_ timers from the list, so we don't have to detach them individually. */
	list_for_each_entry_safe(timer, tmp, &tv_list, entry) {
		internal_add_timer(base, timer);
	}
	return index;
}


1. Context — Why cascade?

The timer wheel (tv1..tv5) is hierarchical.
tv1 handles near-future timers (fine granularity).
tv2 handles timers farther out.
When tv1 wraps (index rolls over to 0), one "slot" from tv2 is cascaded down to refill tv1.
So when INDEX(0) is reached:
Slot 0 of tv2 is cascaded into tv1.

2. What cascade(base, &base->tv2, INDEX(0)) does
Suppose tv2.vec[0] looks like this:
tv2.vec[0] → T1 → T2 → T3

These timers were originally placed in tv2 because their expiry was too far in the future to fit inside tv1’s range.
Now enough time has passed (tv1 rolled over), so they need to be reconsidered.

3. Step by step
Step 1: Move list
list_replace_init(tv->vec + index, &tv_list);

Now:
tv2.vec[0] becomes empty.
tv_list holds → T1 → T2 → T3.

Step 2: Reinsert timers
list_for_each_entry_safe(timer, tmp, &tv_list, entry) {
    internal_add_timer(base, timer);
}

Each timer is now re-added via internal_add_timer().
That function checks the remaining expiry time vs. base->timer_jiffies and decides:
If the expiry is now within tv1’s range → goes into the correct slot in tv1.vec.
Otherwise → still belongs to tv2 (or even deeper), so it gets placed back there.

4. Concrete Example
Let’s say:
jiffies = 512.
tv1 covers the next 256 ticks (512..767).
tv2 slot 0 holds timers expiring at 600, 650, 700.

Diagram before cascade:
tv1 (covers 512..767): [empty slots so far]
tv2.vec[0]: → T1(exp=600) → T2(exp=650) → T3(exp=700)
When cascade(base, &base->tv2, 0) runs:
Slot tv2.vec[0] emptied into tv_list.
Each timer re-added:
T1(600) → fits into tv1.vec[88] (600 - 512 = 88).
T2(650) → fits into tv1.vec[138].
T3(700) → fits into tv1.vec[188].

Diagram after cascade:
tv1.vec[88] → T1
tv1.vec[138] → T2
tv1.vec[188] → T3
tv2.vec[0] → empty

✅ That’s how cascade() + internal_add_timer() move timers down:
Cascade empties a slot.
internal_add_timer redistributes each timer to the right place, possibly in a lower level.
